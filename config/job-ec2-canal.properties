# for emr ec2
aws_region = us-east-1
s3_endpoint = s3.us-east-1.amazonaws.com
checkpoint_location = s3://panchao-data/spark-redshift-cdc-ec2/checkpoint-test-canal/
checkpoint_interval = availableNow
kafka_broker = b-1.commonmskpanchao.wp46nn.c9.kafka.us-east-1.amazonaws.com:9092
topic = canal_cdc_mysql
startingOffsets = earliest
thread_max_workers = 50
disable_msg = false
# FLINK-CDC or DMS-CDC or MSK-DEBEZIUM-CDC
cdc_format = CANAL-CDC
max_offsets_per_trigger = 1000000
consumer_group = canal-cdc-redshift-ec2-g1
# write s3 temp file format, CSV,CSV GZIP,JSON, JSON GZIP. default CSV
tempformat = CSV
# copy redshift max error record
maxerror = 0
redshift_secret_id =
redshift_host = stress-4x.cgpqploshmmo.us-east-1.redshift.amazonaws.com
redshift_port = 5439
redshift_username = ssa
redshift_password = Ssa123456
redshift_database = dev
redshift_schema = cdc_data_04
redshift_tmpdir = s3://panchao-data/spark-redshift-cdc-ec2/tmpdir/
redshift_iam_role = arn:aws:iam::946277762357:role/admin-role-panchao


sync_table_list = [\
{"db": "prodb01", "table": "product_mark_19", "primary_key": "itemcode"},\
{"db": "prodb04", "table": "prod_score_c4", "primary_key": "itemcode"},\
{"db": "prodb04_e0", "table": "product_sku_e7", "primary_key": "sku_id"}\
]